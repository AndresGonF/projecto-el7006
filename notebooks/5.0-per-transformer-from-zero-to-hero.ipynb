{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agonzalez/miniconda3/envs/el7006/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "project_path = os.path.abspath('..')\n",
    "sys.path.insert(1, project_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "# import seaborn\n",
    "# seaborn.set_context(context=\"talk\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math, copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.data.dataset import lc_dataset\n",
    "from src.models.model import periodicTransformer\n",
    "from src.visualization.plots import plot_periodic\n",
    "from src.data.curve_generator import random_periodic_sin_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len= 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        print(position.shape)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        print(div_term.shape)\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        print(self.pe[:x.size(0)].shape)\n",
    "        print(x.shape)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        print(x.shape)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add + norm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dropout=0.1, d_model=240, d_ff=128, h=8):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.mod = torch.nn.Linear(1, d_model)\n",
    "        self.linear1 = torch.nn.Linear(d_model, d_model)\n",
    "        self.att = torch.nn.MultiheadAttention(d_model, h)\n",
    "\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff)\n",
    "        self.sublayer = clones(SublayerConnection(d_model, dropout), 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = x.float()\n",
    "        x = self.sublayer[0](x, lambda x: self.att(x, x, x)[0])\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFilm(nn.Module):\n",
    "    def __init__(self, n_harmonics=7, embedding_size=64, T_max=1000.0, input_size = 1):\n",
    "        super(TimeFilm, self).__init__()\n",
    "\n",
    "        self.a = nn.parameter.Parameter(\n",
    "            torch.rand(n_harmonics, embedding_size), requires_grad=True)\n",
    "        self.b = nn.parameter.Parameter(\n",
    "            torch.rand(n_harmonics, embedding_size), requires_grad=True)\n",
    "        self.w = nn.parameter.Parameter(\n",
    "            torch.rand(n_harmonics, embedding_size), requires_grad=True)\n",
    "        self.v = nn.parameter.Parameter(\n",
    "            torch.rand(n_harmonics, embedding_size),  requires_grad=True)\n",
    "\n",
    "        self.linear_proj = nn.Sequential(nn.Linear(in_features= input_size, out_features=embedding_size, bias=False),\n",
    "                                         nn.LeakyReLU(0.1))\n",
    "\n",
    "        self.linear_proj_ = nn.Sequential(nn.Linear(in_features=embedding_size, out_features=embedding_size, bias=False),\n",
    "                                          nn.LeakyReLU(0.1))\n",
    "        self.n_ = nn.parameter.Parameter(\n",
    "            torch.linspace(1, n_harmonics+1, steps=n_harmonics) / T_max, requires_grad=False)\n",
    "\n",
    "    def harmonics(self, t):\n",
    "        \"\"\" t [n_batch, length sequence, 1, n_harmonics]\"\"\"\n",
    "\n",
    "        return t[:, :, :, None]*2*np.pi*self.n_\n",
    "\n",
    "    def fourier_coefs(self, t):\n",
    "\n",
    "        t_harmonics = self.harmonics(t)\n",
    "\n",
    "        gama_ = torch.tanh(torch.matmul(torch.sin(t_harmonics), self.a) + \\\n",
    "            torch.matmul(torch.cos(t_harmonics), self.b))\n",
    "\n",
    "        beta_ = torch.matmul(torch.sin(t_harmonics), self.v) + \\\n",
    "            torch.matmul(torch.cos(t_harmonics), self.w)\n",
    "\n",
    "        return gama_, beta_\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\" t must be of size [n_batch, length sequence]\"\"\"\n",
    "        print(t.dtype)\n",
    "\n",
    "        gama_, beta_ = self.fourier_coefs(t)\n",
    "\n",
    "        # self.linear_proj_(self.linear_proj(x[:, :, None])*torch.tanh(torch.squeeze(gama_)) + torch.squeeze(beta_))\n",
    "        return self.linear_proj_(self.linear_proj(x)*torch.squeeze(gama_) + torch.squeeze(beta_))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodingSousa(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=200, max_time=1000.0, max_len= 5000):\n",
    "        super(PositionalEncodingSousa, self).__init__()\n",
    "        self.div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(max_time) / d_model))\n",
    "        self.pe = torch.zeros(max_len, 1000, d_model)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        argument = t * self.div_term\n",
    "        self.pe[:, :, 0::2] = torch.sin(argument)\n",
    "        self.pe[:, :, 1::2] = torch.cos(argument)\n",
    "        self.register_buffer('pe', self.pe)        \n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class periodicTransformer(nn.Module):\n",
    "    def __init__(self, n_classes=5, d_model=200, d_ff=128, h=8, N=4, time='discrete'):\n",
    "        super().__init__()\n",
    "        self.time = time\n",
    "        self.pos_enc_discrete = PositionalEncoding(d_model)\n",
    "        self.pos_enc_continuous = TimeFilm(embedding_size=d_model)\n",
    "        self.enc_blocks = clones(EncoderBlock(d_model=d_model, d_ff=d_ff, h=h), N)\n",
    "        self.proj = nn.Linear(d_model, n_classes)\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform(p)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if self.time == 'continuous':\n",
    "            x = self.pos_enc_continuous(x, t)\n",
    "        else:\n",
    "            x = self.pos_enc_discrete(x)\n",
    "        for enc in self.enc_blocks:\n",
    "            x = enc(x)\n",
    "        x = self.proj(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 1])\n",
      "torch.Size([100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18220/4208361457.py:11: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n"
     ]
    }
   ],
   "source": [
    "d_model = 200\n",
    "\n",
    "temp = periodicTransformer(d_model=d_model, time='countinuos').double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lc_dataset()\n",
    "data.add_curves('sinmix', N=800, seq_len=60, min_period=0.5, max_period=2, label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "data_loader = DataLoader(data,\n",
    "                        batch_size=batch_size,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=16,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(data_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 200])\n",
      "torch.Size([2, 60])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (60) must match the size of tensor b (200) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m temp(batch[\u001b[39m'\u001b[39;49m\u001b[39mmag\u001b[39;49m\u001b[39m'\u001b[39;49m], batch[\u001b[39m'\u001b[39;49m\u001b[39mmjd\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/el7006/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb Cell 23\u001b[0m in \u001b[0;36mperiodicTransformer.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc_continuous(x, t)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_enc_discrete(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m enc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc_blocks:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m enc(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/el7006/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb Cell 23\u001b[0m in \u001b[0;36mPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpe[:x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpe[:x\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m)]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agonzalez/projects/el7006/Projecto-EL7006/notebooks/5.0-per-transformer-from-zero-to-hero.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (60) must match the size of tensor b (200) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "temp(batch['mag'], batch['mjd'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "el7006",
   "language": "python",
   "name": "el7006"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
